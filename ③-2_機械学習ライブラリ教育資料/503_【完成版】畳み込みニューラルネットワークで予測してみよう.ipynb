{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "503_【完成版】畳み込みニューラルネットワークで予測してみよう.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6X6DgHjOx3o",
        "colab_type": "text"
      },
      "source": [
        "# 学習済みモデルを使って表情認識をしてみよう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt6bNJLKO0hP",
        "colab_type": "text"
      },
      "source": [
        "## 使用するデータを準備しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-u1VtsXVhIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "Path = glob(\"/content/drive/My Drive/Colab Notebooks/test/\")\n",
        "\n",
        "# 空のリストを準備\n",
        "file_name = []\n",
        "data = []\n",
        "\n",
        "\n",
        "# 画像サイズ\n",
        "image_size = 28\n",
        "\n",
        "def append_data(directory):\n",
        "    files = os.listdir(directory)  # ディレクトリの中をファイルを全てリストにする\n",
        "    for image in files:\n",
        "        file_name.append(image)\n",
        "        if image.endswith(\".jpg\"): # jpg画像だけを抽出\n",
        "            image = cv2.imread(directory + image) # 画像を準備\n",
        "            image = cv2.resize(image, (image_size, image_size)) # リサイズ\n",
        "            image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # グレースケール\n",
        "            image_gs = image_gs.flatten() # リストを平坦化     \n",
        "            data.append(image_gs)  # 学習用データに代入\n",
        "                \n",
        "for fil in Path:\n",
        "    append_data(fil)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYYi8-cqO9So",
        "colab_type": "text"
      },
      "source": [
        "## CNNに適用する型に変更しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8vyjprajSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データ型を変更\n",
        "data = np.array(data, dtype=np.float32)\n",
        "\n",
        "data = data.reshape((len(data)),image_size,image_size,1)\n",
        "\n",
        "data /= 255 # to 0-1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORUJblWcPJRK",
        "colab_type": "text"
      },
      "source": [
        "## ニューラルネットワークのモデルを復元しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSM_quBbRht-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# モデルのロード\n",
        "mymodel = keras.models.load_model('/content/drive/My Drive/my_model.h5',\n",
        "                                  compile=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e71b5bFOPSUn",
        "colab_type": "text"
      },
      "source": [
        "## モデル構成を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p50fpgftXxyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "bea7fddc-02ec-4471-e335-03c72286bd37"
      },
      "source": [
        "mymodel.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 28, 28, 20)        520       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 14, 14, 20)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 14, 14, 50)        25050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 2450)              0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 500)               1225500   \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 5)                 2505      \n",
            "=================================================================\n",
            "Total params: 1,504,075\n",
            "Trainable params: 1,504,075\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDbPEK4jPXV-",
        "colab_type": "text"
      },
      "source": [
        "## 実行プログラムを作成しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewqQaF3GZSMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "73d872a3-3fe3-4557-dc71-e3ce5d367110"
      },
      "source": [
        "predict = mymodel.predict(data)\n",
        "\n",
        "for fil, pred in zip(file_name, predict):\n",
        "    pred_index = np.argmax(pred)\n",
        "    if pred_index == 0:\n",
        "        print(str(fil)+\" :surprised\")\n",
        "    elif pred_index == 1:\n",
        "        print(str(fil)+\":sad\")\n",
        "    elif pred_index == 2:\n",
        "        print(str(fil)+\" :neutral\")\n",
        "    elif pred_index == 3:\n",
        "        print(str(fil)+\":happy\")\n",
        "    else:\n",
        "        print(str(fil)+\":angry\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HA_101.jpg: happy\n",
            "AN_101.jpg: angry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbygZO04ZWOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}